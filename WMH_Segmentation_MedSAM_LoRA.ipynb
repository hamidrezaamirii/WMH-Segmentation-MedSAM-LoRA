{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ðŸ§  WMH-LoRA: Parameter-Efficient FLAIR-Only WMH Segmentation\n",
        "\n",
        "**Automated white matter hyperintensity segmentation using MedSAM with Low-Rank Adaptation (LoRA) â€” achieving 0.78 Dice Score using single-modality FLAIR MRI and only 3.5% trainable parameters.**\n",
        "\n",
        "[![View on GitHub](https://img.shields.io/badge/View%20on-GitHub-181717?logo=github&logoColor=white)](https://github.com/hamidrezaamirii/WMH-Segmentation-MedSAM-LoRA) Â·\n",
        "[![WMH Challenge](https://img.shields.io/badge/Benchmark-WMH%20Challenge-blue)](https://wmh.isi.uu.nl/) Â·\n",
        "[![MedSAM Paper](https://img.shields.io/badge/Foundation-MedSAM-green)](https://arxiv.org/abs/2304.12306)"
      ],
      "metadata": {
        "id": "C7ZpFxPpecGH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTRNZukmMkHs"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# WMH Segmentation â€” Ultimate Version\n",
        "# Med-SAM ViT-B + High-Rank LoRA + Advanced Training\n",
        "# Target: 0.80-0.85+ Dice | Colab Pro A100/V100\n",
        "# ============================================================\n",
        "\n",
        "# %% [markdown]\n",
        "# # 1. Environment\n",
        "\n",
        "# %%\n",
        "!pip install nibabel monai segment-anything timm gdown kagglehub scipy -q\n",
        "\n",
        "# %%\n",
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "os.environ['KAGGLE_USERNAME'] = 'Your_USERNAME'\n",
        "os.environ['KAGGLE_KEY']      = 'Your_KEY'\n",
        "\n",
        "import gc, math, json, time, shutil, zipfile\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.utils.checkpoint import checkpoint as grad_checkpoint\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as mcolors\n",
        "from matplotlib.patches import Patch\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "import warnings; warnings.filterwarnings('ignore')\n",
        "\n",
        "import nibabel as nib\n",
        "import monai\n",
        "from monai.transforms import (\n",
        "    Compose, LoadImaged, EnsureChannelFirstd,\n",
        "    Orientationd, Spacingd,\n",
        ")\n",
        "from segment_anything import sam_model_registry\n",
        "from scipy.ndimage import label as scipy_label\n",
        "from scipy.ndimage import generate_binary_structure\n",
        "\n",
        "print(f\"PyTorch: {torch.__version__} | MONAI: {monai.__version__}\")\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "if torch.cuda.is_available():\n",
        "    props = torch.cuda.get_device_properties(0)\n",
        "    vram = getattr(props, 'total_memory',\n",
        "                   getattr(props, 'total_mem', 0))\n",
        "    gpu_name = props.name\n",
        "    print(f\"GPU: {gpu_name} | VRAM: {vram/1e9:.1f} GB\")\n",
        "else:\n",
        "    gpu_name = \"CPU\"\n",
        "    vram = 0\n",
        "    print(\"âš  NO GPU\")\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# ============================================================\n",
        "# ADAPTIVE CONFIG based on GPU\n",
        "# ============================================================\n",
        "IS_A100 = 'A100' in gpu_name\n",
        "IS_V100 = 'V100' in gpu_name\n",
        "IS_HIGHEND = IS_A100 or IS_V100 or vram > 20e9\n",
        "\n",
        "if IS_A100:\n",
        "    IMG_SIZE = 512\n",
        "    BATCH_SIZE = 4\n",
        "    ACCUM_STEPS = 4      # effective batch = 16\n",
        "    LORA_RANK = 64\n",
        "    NUM_WORKERS = 4\n",
        "    GRAD_CKPT = False     # A100 has plenty of VRAM\n",
        "    print(\"â†’ A100 config: batch=4, accum=4, rank=64, no grad_ckpt\")\n",
        "elif IS_V100 or vram > 20e9:\n",
        "    IMG_SIZE = 512\n",
        "    BATCH_SIZE = 2\n",
        "    ACCUM_STEPS = 8      # effective batch = 16\n",
        "    LORA_RANK = 48\n",
        "    NUM_WORKERS = 4\n",
        "    GRAD_CKPT = False\n",
        "    print(\"â†’ V100 config: batch=2, accum=8, rank=48\")\n",
        "else:\n",
        "    IMG_SIZE = 512\n",
        "    BATCH_SIZE = 1\n",
        "    ACCUM_STEPS = 16     # effective batch = 16\n",
        "    LORA_RANK = 32\n",
        "    NUM_WORKERS = 2\n",
        "    GRAD_CKPT = True\n",
        "    print(\"â†’ Standard config: batch=1, accum=16, rank=32, grad_ckpt\")\n",
        "\n",
        "LORA_ALPHA = float(LORA_RANK)  # alpha = rank is standard\n",
        "EPOCHS = 100\n",
        "BASE_LR = 3e-4\n",
        "WEIGHT_DECAY = 0.01\n",
        "WARMUP_EPOCHS = 5\n",
        "RESTART_PERIOD = 25   # cosine restart every 25 epochs\n",
        "BG_RATIO_TRAIN = 0.08\n",
        "BG_RATIO_VAL = 0.15\n",
        "CHECKPOINT_EVERY = 10\n",
        "\n",
        "print(f\"Effective batch: {BATCH_SIZE * ACCUM_STEPS}\")\n",
        "print(f\"LoRA: rank={LORA_RANK}, alpha={LORA_ALPHA}\")\n",
        "print(f\"Epochs: {EPOCHS}, restarts every {RESTART_PERIOD}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# # 2. Drive Mount + Backup Dir\n",
        "\n",
        "# %%\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=False)\n",
        "\n",
        "BACKUP_DIR = \"/content/drive/MyDrive/WMH_ultimate\"\n",
        "os.makedirs(BACKUP_DIR, exist_ok=True)\n",
        "\n",
        "# Check for existing checkpoints to resume from\n",
        "RESUME_EPOCH = 0\n",
        "RESUME_CKPT = None\n",
        "for ep in range(EPOCHS, 0, -1):\n",
        "    ckpt_path = f\"{BACKUP_DIR}/checkpoint_ep{ep:03d}.pth\"\n",
        "    if os.path.exists(ckpt_path) and \\\n",
        "       os.path.getsize(ckpt_path) > 50000:\n",
        "        RESUME_CKPT = ckpt_path\n",
        "        RESUME_EPOCH = ep\n",
        "        break\n",
        "\n",
        "if RESUME_CKPT:\n",
        "    print(f\"âœ“ Found checkpoint at epoch {RESUME_EPOCH}: {RESUME_CKPT}\")\n",
        "    print(f\"  Will resume training from epoch {RESUME_EPOCH + 1}\")\n",
        "else:\n",
        "    # Check old backup dir\n",
        "    OLD_BACKUP = \"/content/drive/MyDrive/WMH_backup\"\n",
        "    if os.path.exists(f\"{OLD_BACKUP}/best_flair_lora.pth\"):\n",
        "        print(\"Found previous best_flair_lora.pth \"\n",
        "              \"(old rank=4, won't load into rank=64)\")\n",
        "    print(\"Starting fresh training\")\n",
        "\n",
        "# %% [markdown]\n",
        "# # 3. Med-SAM Download\n",
        "\n",
        "# %%\n",
        "import gdown\n",
        "\n",
        "MEDSAM_CHECKPOINT = \"/content/medsam_vit_b.pth\"\n",
        "\n",
        "# Try drive first\n",
        "for src in [f\"{BACKUP_DIR}/medsam_vit_b.pth\",\n",
        "            \"/content/drive/MyDrive/WMH_backup/medsam_vit_b.pth\"]:\n",
        "    if os.path.exists(src) and os.path.getsize(src) > 100_000_000:\n",
        "        if not os.path.exists(MEDSAM_CHECKPOINT):\n",
        "            shutil.copy2(src, MEDSAM_CHECKPOINT)\n",
        "        print(f\"âœ“ Med-SAM from Drive\")\n",
        "        break\n",
        "else:\n",
        "    if not (os.path.exists(MEDSAM_CHECKPOINT) and\n",
        "            os.path.getsize(MEDSAM_CHECKPOINT) > 100_000_000):\n",
        "        print(\"Downloading Med-SAM ViT-B...\")\n",
        "        gdown.download(id=\"1UAmWL88roYR7wKlnApw5Bcuzf2iQgk6_\",\n",
        "                       output=MEDSAM_CHECKPOINT, quiet=False)\n",
        "\n",
        "sz = os.path.getsize(MEDSAM_CHECKPOINT)\n",
        "assert sz > 100_000_000, f\"Med-SAM corrupted ({sz} bytes)\"\n",
        "print(f\"âœ“ Med-SAM: {sz/1e6:.0f} MB\")\n",
        "\n",
        "# Backup\n",
        "if not os.path.exists(f\"{BACKUP_DIR}/medsam_vit_b.pth\"):\n",
        "    shutil.copy2(MEDSAM_CHECKPOINT,\n",
        "                 f\"{BACKUP_DIR}/medsam_vit_b.pth\")\n",
        "\n",
        "# %% [markdown]\n",
        "# # 4. Data Pipeline\n",
        "\n",
        "# %%\n",
        "import kagglehub\n",
        "\n",
        "DATA_DIR = \"/content/wmh_flair_only\"\n",
        "KAGGLE_DATASET_ID = \"farahmo/wmh-dataset\"\n",
        "USE_SYNTHETIC = False\n",
        "\n",
        "\n",
        "def filter_to_flair(src_dir, dst_dir):\n",
        "    \"\"\"Copy only FLAIR + WMH mask NIfTIs.\"\"\"\n",
        "    src = Path(src_dir)\n",
        "    dst = Path(dst_dir)\n",
        "    KEEP = {'flair', 'wmh'}\n",
        "    copied = 0\n",
        "    for root, dirs, files in os.walk(src):\n",
        "        for fname in files:\n",
        "            sf = Path(root) / fname\n",
        "            fl = fname.lower()\n",
        "            if not (fl.endswith('.nii.gz') or fl.endswith('.nii')):\n",
        "                continue\n",
        "            if any(k in fl for k in KEEP):\n",
        "                rel = sf.relative_to(src)\n",
        "                df = dst / rel\n",
        "                df.parent.mkdir(parents=True, exist_ok=True)\n",
        "                shutil.copy2(sf, df)\n",
        "                copied += 1\n",
        "    return copied\n",
        "\n",
        "\n",
        "# Strategy 1: Restore from Drive zip\n",
        "restored = False\n",
        "for zip_src in [f\"{BACKUP_DIR}/wmh_filtered_data.zip\",\n",
        "                \"/content/drive/MyDrive/WMH_backup/\"\n",
        "                \"wmh_filtered_data.zip\"]:\n",
        "    if os.path.exists(zip_src) and os.path.getsize(zip_src) > 1e6:\n",
        "        if not os.path.isdir(DATA_DIR) or \\\n",
        "           len(list(Path(DATA_DIR).rglob(\"*.nii*\"))) == 0:\n",
        "            print(f\"Extracting {zip_src}...\")\n",
        "            os.makedirs(DATA_DIR, exist_ok=True)\n",
        "            with zipfile.ZipFile(zip_src, 'r') as z:\n",
        "                z.extractall(DATA_DIR)\n",
        "        n = len(list(Path(DATA_DIR).rglob(\"*.nii*\")))\n",
        "        if n > 0:\n",
        "            print(f\"âœ“ Restored {n} NIfTI files from Drive\")\n",
        "            restored = True\n",
        "            break\n",
        "\n",
        "# Strategy 2: Download from Kaggle\n",
        "if not restored:\n",
        "    uname = os.environ.get('KAGGLE_USERNAME', '')\n",
        "    key = os.environ.get('KAGGLE_KEY', '')\n",
        "    if uname and uname != 'YOUR_KAGGLE_USERNAME' and \\\n",
        "       key and key != 'YOUR_KAGGLE_API_KEY':\n",
        "        print(\"Downloading from Kaggle...\")\n",
        "        try:\n",
        "            raw = kagglehub.dataset_download(KAGGLE_DATASET_ID)\n",
        "            print(f\"Downloaded to: {raw}\")\n",
        "            os.makedirs(DATA_DIR, exist_ok=True)\n",
        "            n = filter_to_flair(raw, DATA_DIR)\n",
        "            print(f\"Filtered: {n} files\")\n",
        "            shutil.rmtree(raw, ignore_errors=True)\n",
        "            gc.collect()\n",
        "            # Backup zip\n",
        "            print(\"Backing up zip to Drive...\")\n",
        "            shutil.make_archive(\n",
        "                f\"{BACKUP_DIR}/wmh_filtered_data\", 'zip', DATA_DIR)\n",
        "            print(\"âœ“ Backed up\")\n",
        "            restored = True\n",
        "        except Exception as e:\n",
        "            print(f\"Kaggle failed: {e}\")\n",
        "    else:\n",
        "        print(\"âš  No Kaggle credentials\")\n",
        "\n",
        "# Strategy 3: Synthetic\n",
        "if not restored or not os.path.isdir(DATA_DIR) or \\\n",
        "   len(list(Path(DATA_DIR).rglob(\"*.nii*\"))) == 0:\n",
        "    USE_SYNTHETIC = True\n",
        "    DATA_DIR = \"/content/synthetic_wmh\"\n",
        "    print(\"Using synthetic data\")\n",
        "\n",
        "\n",
        "def create_synthetic(data_dir, n_per_site=7):\n",
        "    data_dir = Path(data_dir)\n",
        "    sites = {\n",
        "        \"Utrecht\":   {\"voxel\":(0.96,0.96,3.0),\n",
        "                      \"shape\":(132,256,83)},\n",
        "        \"Singapore\": {\"voxel\":(1.0,1.0,3.0),\n",
        "                      \"shape\":(252,232,48)},\n",
        "        \"GE3T\":      {\"voxel\":(0.98,0.98,1.2),\n",
        "                      \"shape\":(132,256,83)},\n",
        "    }\n",
        "    for site, info in sites.items():\n",
        "        sh = info[\"shape\"]\n",
        "        aff = np.diag(list(info[\"voxel\"])+[1.0])\n",
        "        for idx in range(n_per_site):\n",
        "            pre = data_dir/site/str(idx)/\"pre\"\n",
        "            pre.mkdir(parents=True, exist_ok=True)\n",
        "            sd = pre.parent\n",
        "            rng = np.random.RandomState(\n",
        "                hash(f\"{site}_{idx}\")%2**31)\n",
        "            zz,yy,xx = np.mgrid[0:sh[0],0:sh[1],0:sh[2]]\n",
        "            cz,cy,cx = [s//2 for s in sh]\n",
        "            rz,ry,rx = [s*0.4 for s in sh]\n",
        "            brain = (((zz-cz)/rz)**2+((yy-cy)/ry)**2+\n",
        "                     ((xx-cx)/rx)**2) < 1\n",
        "            flair = np.zeros(sh, np.float32)\n",
        "            flair[brain] = 700 + rng.randn(brain.sum())*180\n",
        "            flair = np.clip(flair, 0, None)\n",
        "            mask = np.zeros(sh, np.float32)\n",
        "            for _ in range(rng.randint(5, 25)):\n",
        "                lx = rng.randint(max(1,int(cz-rz*.6)),\n",
        "                                 min(sh[0]-1,int(cz+rz*.6)))\n",
        "                ly = rng.randint(max(1,int(cy-ry*.6)),\n",
        "                                 min(sh[1]-1,int(cy+ry*.6)))\n",
        "                lz = rng.randint(max(1,int(cx-rx*.6)),\n",
        "                                 min(sh[2]-1,int(cx+rx*.6)))\n",
        "                sr = rng.randint(1, 6, size=3)\n",
        "                xs = slice(max(lx-sr[0],0),min(lx+sr[0],sh[0]))\n",
        "                ys = slice(max(ly-sr[1],0),min(ly+sr[1],sh[1]))\n",
        "                zs = slice(max(lz-sr[2],0),min(lz+sr[2],sh[2]))\n",
        "                v = brain[xs,ys,zs]\n",
        "                mask[xs,ys,zs][v] = 1.0\n",
        "                flair[xs,ys,zs][v] += 400 + rng.rand()*200\n",
        "            nib.save(nib.Nifti1Image(flair, aff),\n",
        "                     pre/\"FLAIR.nii.gz\")\n",
        "            nib.save(nib.Nifti1Image(mask, aff),\n",
        "                     sd/\"wmh.nii.gz\")\n",
        "    print(f\"Created {n_per_site*3} synthetic subjects\")\n",
        "\n",
        "if USE_SYNTHETIC:\n",
        "    create_synthetic(DATA_DIR, n_per_site=7)\n",
        "\n",
        "print(f\"Data: {DATA_DIR}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# # 5. Subject Discovery + Split\n",
        "\n",
        "# %%\n",
        "class WMHCatalog:\n",
        "    SITE_ALIASES = {\n",
        "        \"Utrecht\": [\"Utrecht\",\"utrecht\",\"UTRECHT\"],\n",
        "        \"Singapore\": [\"Singapore\",\"singapore\",\"SINGAPORE\"],\n",
        "        \"GE3T\": [\"GE3T\",\"ge3t\",\"Amsterdam\",\"amsterdam\",\n",
        "                 \"GE3T_Amsterdam\",\"GE\"],\n",
        "    }\n",
        "\n",
        "    def __init__(self, root):\n",
        "        self.root = Path(root)\n",
        "        self.subjects = []\n",
        "        self._discover()\n",
        "\n",
        "    def _discover(self):\n",
        "        roots = [self.root]\n",
        "        for c in self.root.iterdir():\n",
        "            if c.is_dir():\n",
        "                roots.append(c)\n",
        "                for cc in c.iterdir():\n",
        "                    if cc.is_dir(): roots.append(cc)\n",
        "\n",
        "        found = {}\n",
        "        for r in roots:\n",
        "            if not r.is_dir(): continue\n",
        "            for sn, als in self.SITE_ALIASES.items():\n",
        "                for a in als:\n",
        "                    d = r / a\n",
        "                    if d.is_dir() and sn not in found:\n",
        "                        found[sn] = d\n",
        "\n",
        "        if not found:\n",
        "            self._flat()\n",
        "            return\n",
        "\n",
        "        for site, sdir in sorted(found.items()):\n",
        "            for sd in sorted(sdir.iterdir()):\n",
        "                if not sd.is_dir(): continue\n",
        "                e = self._find(sd, site)\n",
        "                if e: self.subjects.append(e)\n",
        "\n",
        "        print(f\"Found {len(self.subjects)} subjects\")\n",
        "        ct = defaultdict(int)\n",
        "        for s in self.subjects: ct[s['site']] += 1\n",
        "        for s, n in sorted(ct.items()): print(f\"  {s}: {n}\")\n",
        "\n",
        "    def _flat(self):\n",
        "        fmap, mmap = {}, {}\n",
        "        for f in self.root.rglob(\"*.nii*\"):\n",
        "            nl = f.name.lower()\n",
        "            k = str(f.parent)\n",
        "            if 'flair' in nl: fmap[k] = f\n",
        "            elif 'wmh' in nl: mmap[k] = f\n",
        "        for k in fmap:\n",
        "            mk = mmap.get(k) or mmap.get(str(Path(k).parent))\n",
        "            if not mk: continue\n",
        "            site = \"Unknown\"\n",
        "            kl = k.lower()\n",
        "            if 'utrecht' in kl: site = \"Utrecht\"\n",
        "            elif 'singapore' in kl: site = \"Singapore\"\n",
        "            elif 'ge3t' in kl or 'amsterdam' in kl: site = \"GE3T\"\n",
        "            self.subjects.append({\n",
        "                \"flair\": str(fmap[k]), \"mask\": str(mk),\n",
        "                \"site\": site,\n",
        "                \"subject_id\": f\"{site}_{Path(k).name}\"})\n",
        "        print(f\"Found {len(self.subjects)} subjects (flat)\")\n",
        "\n",
        "    def _find(self, sd, site):\n",
        "        flair = mask = None\n",
        "        for d in [sd/\"pre\", sd]:\n",
        "            if not d.is_dir(): continue\n",
        "            for f in d.iterdir():\n",
        "                if not f.is_file(): continue\n",
        "                nl = f.name.lower()\n",
        "                if not nl.endswith(('.nii.gz','.nii')): continue\n",
        "                if 'flair' in nl and not flair: flair = f\n",
        "        for f in sd.iterdir():\n",
        "            if f.is_file():\n",
        "                nl = f.name.lower()\n",
        "                if nl.endswith(('.nii.gz','.nii')):\n",
        "                    if any(x in nl for x in ['wmh','label','seg']):\n",
        "                        mask = f; break\n",
        "        if not mask:\n",
        "            for f in sd.parent.iterdir():\n",
        "                if f.is_file() and 'wmh' in f.name.lower():\n",
        "                    mask = f; break\n",
        "        if not flair or not mask: return None\n",
        "        return {\"flair\": str(flair), \"mask\": str(mask),\n",
        "                \"site\": site,\n",
        "                \"subject_id\": f\"{site}_{sd.name}\"}\n",
        "\n",
        "\n",
        "catalog = WMHCatalog(DATA_DIR)\n",
        "\n",
        "\n",
        "def stratified_split(subjects, train_r=0.7, val_r=0.15, seed=42):\n",
        "    rng = np.random.RandomState(seed)\n",
        "    by_site = defaultdict(list)\n",
        "    for s in subjects: by_site[s['site']].append(s)\n",
        "    tr, va, te = [], [], []\n",
        "    for site, sl in sorted(by_site.items()):\n",
        "        n = len(sl); idx = rng.permutation(n)\n",
        "        nt = max(1, round(n*train_r))\n",
        "        nv = max(1, round(n*val_r))\n",
        "        nte = max(1, n-nt-nv)\n",
        "        while nt+nv+nte > n: nt -= 1\n",
        "        while nt+nv+nte < n: nt += 1\n",
        "        for i in idx[:nt]: tr.append(sl[i])\n",
        "        for i in idx[nt:nt+nv]: va.append(sl[i])\n",
        "        for i in idx[nt+nv:]: te.append(sl[i])\n",
        "        print(f\"  {site:12s}: {nt} tr, {nv} val, {nte} test\")\n",
        "    print(f\"Total: {len(tr)} / {len(va)} / {len(te)}\")\n",
        "    return tr, va, te\n",
        "\n",
        "\n",
        "# Try loading saved splits\n",
        "splits_loaded = False\n",
        "for sp in [f\"{BACKUP_DIR}/full_state.json\",\n",
        "           \"/content/drive/MyDrive/WMH_backup/full_state.json\"]:\n",
        "    if os.path.exists(sp):\n",
        "        try:\n",
        "            with open(sp) as f:\n",
        "                st = json.load(f)\n",
        "            if \"train_subj\" in st:\n",
        "                # Verify paths exist\n",
        "                test_f = st[\"train_subj\"][0].get(\"flair\", \"\")\n",
        "                if os.path.exists(test_f):\n",
        "                    train_subj = st[\"train_subj\"]\n",
        "                    val_subj = st[\"val_subj\"]\n",
        "                    test_subj = st[\"test_subj\"]\n",
        "                    splits_loaded = True\n",
        "                    print(f\"âœ“ Loaded splits: \"\n",
        "                          f\"{len(train_subj)}/{len(val_subj)}/\"\n",
        "                          f\"{len(test_subj)}\")\n",
        "                    break\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "if not splits_loaded:\n",
        "    print(\"Generating split (seed=42):\")\n",
        "    train_subj, val_subj, test_subj = stratified_split(\n",
        "        catalog.subjects)\n",
        "\n",
        "# Save splits\n",
        "state_save = {\n",
        "    \"train_subj\": train_subj,\n",
        "    \"val_subj\": val_subj,\n",
        "    \"test_subj\": test_subj,\n",
        "    \"config\": {\n",
        "        \"img_size\": IMG_SIZE, \"lora_rank\": LORA_RANK,\n",
        "        \"lora_alpha\": LORA_ALPHA, \"epochs\": EPOCHS,\n",
        "        \"lr\": BASE_LR, \"batch\": BATCH_SIZE,\n",
        "        \"accum\": ACCUM_STEPS, \"seed\": 42,\n",
        "    },\n",
        "}\n",
        "with open(f\"{BACKUP_DIR}/full_state.json\", \"w\") as f:\n",
        "    json.dump(state_save, f, indent=2, default=str)\n",
        "\n",
        "# %% [markdown]\n",
        "# # 6. Advanced Dataset with Online Augmentation\n",
        "\n",
        "# %%\n",
        "class WMHDatasetV2(Dataset):\n",
        "    \"\"\"\n",
        "    Improvements over V1:\n",
        "    - Elastic deformation via random affine\n",
        "    - Intensity augmentation (gamma, noise)\n",
        "    - Oversampling of lesion-containing slices\n",
        "    - Per-slice lesion fraction weighting\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, subject_list, slice_size=IMG_SIZE,\n",
        "                 mode='train', bg_ratio=0.05):\n",
        "        self.sz = slice_size\n",
        "        self.mode = mode\n",
        "        self.bg_ratio = bg_ratio\n",
        "        self.spatial_transform = Compose([\n",
        "            LoadImaged(keys=[\"flair\", \"mask\"]),\n",
        "            EnsureChannelFirstd(keys=[\"flair\", \"mask\"]),\n",
        "            Orientationd(keys=[\"flair\", \"mask\"], axcodes=\"RAS\"),\n",
        "            Spacingd(keys=[\"flair\", \"mask\"],\n",
        "                     pixdim=(1.0, 1.0, 1.0),\n",
        "                     mode=(\"bilinear\", \"nearest\")),\n",
        "        ])\n",
        "        self.slices = []\n",
        "        self.meta = {'sites': defaultdict(int),\n",
        "                     'n_les': 0, 'n_bg': 0}\n",
        "        self._prepare(subject_list)\n",
        "\n",
        "    @staticmethod\n",
        "    def _robust_zscore(vol, brain):\n",
        "        if brain.sum() == 0: return vol\n",
        "        v = vol[brain]\n",
        "        lo, hi = np.percentile(v, [0.5, 99.5])\n",
        "        vol = np.clip(vol, lo, hi)\n",
        "        v = vol[brain]\n",
        "        m, s = v.mean(), max(v.std(), 1e-8)\n",
        "        vol = (vol - m) / s\n",
        "        vol[~brain] = 0.0\n",
        "        return vol\n",
        "\n",
        "    def _prepare(self, subjects):\n",
        "        for i, subj in enumerate(subjects):\n",
        "            try:\n",
        "                data = self.spatial_transform({\n",
        "                    \"flair\": subj[\"flair\"],\n",
        "                    \"mask\": subj[\"mask\"]})\n",
        "                flair = np.array(data[\"flair\"][0], np.float32)\n",
        "                mask_raw = np.array(data[\"mask\"][0], np.float32)\n",
        "                wmh = (mask_raw == 1).astype(np.float32)\n",
        "                brain = flair > 0\n",
        "                flair = self._robust_zscore(flair, brain)\n",
        "                self.meta['sites'][subj['site']] += 1\n",
        "                rng = np.random.RandomState(\n",
        "                    hash(subj['subject_id']) % 2**31)\n",
        "\n",
        "                for z in range(flair.shape[-1]):\n",
        "                    fs = flair[:,:,z]\n",
        "                    ms = wmh[:,:,z]\n",
        "                    if (np.abs(fs) > 0.01).sum() / fs.size < 0.05:\n",
        "                        continue\n",
        "                    has_les = ms.sum() > 0\n",
        "                    if has_les:\n",
        "                        self.meta['n_les'] += 1\n",
        "                    elif rng.rand() < self.bg_ratio:\n",
        "                        self.meta['n_bg'] += 1\n",
        "                    else:\n",
        "                        continue\n",
        "\n",
        "                    # Compute lesion fraction for weighting\n",
        "                    les_frac = ms.sum() / max(\n",
        "                        (np.abs(fs) > 0.01).sum(), 1)\n",
        "\n",
        "                    self.slices.append({\n",
        "                        \"flair\": fs.copy(),\n",
        "                        \"mask\": ms.copy(),\n",
        "                        \"subject_id\": subj['subject_id'],\n",
        "                        \"site\": subj['site'],\n",
        "                        \"slice_idx\": z,\n",
        "                        \"has_lesion\": has_les,\n",
        "                        \"les_frac\": float(les_frac),\n",
        "                    })\n",
        "\n",
        "                if (i+1) % 5 == 0 or i == 0:\n",
        "                    print(f\"    [{i+1}/{len(subjects)}] \"\n",
        "                          f\"{subj['subject_id']} â€” \"\n",
        "                          f\"{len(self.slices)} slices\")\n",
        "            except Exception as e:\n",
        "                print(f\"    [{i+1}/{len(subjects)}] \"\n",
        "                      f\"{subj['subject_id']} ERROR: {e}\")\n",
        "\n",
        "        nl, nb = self.meta['n_les'], self.meta['n_bg']\n",
        "        print(f\"  [{self.mode.upper()}] {nl+nb} slices \"\n",
        "              f\"(les:{nl}, bg:{nb})\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.slices)\n",
        "\n",
        "    def _augment_intensity(self, image):\n",
        "        \"\"\"Online intensity augmentation for training.\"\"\"\n",
        "        # Random gamma correction\n",
        "        if torch.rand(1).item() > 0.5:\n",
        "            gamma = torch.empty(1).uniform_(0.7, 1.5).item()\n",
        "            mn = image.min()\n",
        "            rng = image.max() - mn\n",
        "            if rng > 1e-6:\n",
        "                image = ((image - mn) / rng).clamp(0, 1)\n",
        "                image = image.pow(gamma) * rng + mn\n",
        "\n",
        "        # Random Gaussian noise\n",
        "        if torch.rand(1).item() > 0.5:\n",
        "            std = torch.empty(1).uniform_(0.01, 0.08).item()\n",
        "            image = image + torch.randn_like(image) * std\n",
        "\n",
        "        # Random brightness\n",
        "        if torch.rand(1).item() > 0.5:\n",
        "            image = image + torch.empty(1).uniform_(-0.15, 0.15)\n",
        "\n",
        "        # Random contrast\n",
        "        if torch.rand(1).item() > 0.5:\n",
        "            factor = torch.empty(1).uniform_(0.8, 1.3).item()\n",
        "            mean = image.mean()\n",
        "            image = (image - mean) * factor + mean\n",
        "\n",
        "        return image\n",
        "\n",
        "    def _augment_spatial(self, image, mask):\n",
        "        \"\"\"Spatial augmentations for training.\"\"\"\n",
        "        # Horizontal flip\n",
        "        if torch.rand(1).item() > 0.5:\n",
        "            image = torch.flip(image, [-1])\n",
        "            mask = torch.flip(mask, [-1])\n",
        "\n",
        "        # Vertical flip\n",
        "        if torch.rand(1).item() > 0.5:\n",
        "            image = torch.flip(image, [-2])\n",
        "            mask = torch.flip(mask, [-2])\n",
        "\n",
        "        # 90-degree rotation\n",
        "        if torch.rand(1).item() > 0.5:\n",
        "            k = torch.randint(1, 4, (1,)).item()\n",
        "            image = torch.rot90(image, k, [-2, -1])\n",
        "            mask = torch.rot90(mask, k, [-2, -1])\n",
        "\n",
        "        # Random affine (small rotation + scale + translate)\n",
        "        if torch.rand(1).item() > 0.3:\n",
        "            angle = torch.empty(1).uniform_(-15, 15).item()\n",
        "            scale = torch.empty(1).uniform_(0.9, 1.1).item()\n",
        "            tx = torch.empty(1).uniform_(-0.05, 0.05).item()\n",
        "            ty = torch.empty(1).uniform_(-0.05, 0.05).item()\n",
        "\n",
        "            rad = math.radians(angle)\n",
        "            cos_a, sin_a = math.cos(rad)*scale, math.sin(rad)*scale\n",
        "            theta = torch.tensor([\n",
        "                [cos_a, -sin_a, tx],\n",
        "                [sin_a,  cos_a, ty]\n",
        "            ], dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "            grid = F.affine_grid(theta, image.unsqueeze(0).size(),\n",
        "                                 align_corners=False)\n",
        "            image = F.grid_sample(\n",
        "                image.unsqueeze(0), grid,\n",
        "                mode='bilinear', align_corners=False,\n",
        "                padding_mode='zeros').squeeze(0)\n",
        "            mask = F.grid_sample(\n",
        "                mask.unsqueeze(0), grid,\n",
        "                mode='nearest', align_corners=False,\n",
        "                padding_mode='zeros').squeeze(0)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        e = self.slices[idx]\n",
        "        image = torch.from_numpy(\n",
        "            e[\"flair\"]).float().unsqueeze(0)\n",
        "        mask = torch.from_numpy(\n",
        "            e[\"mask\"]).float().unsqueeze(0)\n",
        "\n",
        "        image = F.interpolate(\n",
        "            image.unsqueeze(0), (self.sz, self.sz),\n",
        "            mode='bilinear', align_corners=False).squeeze(0)\n",
        "        mask = F.interpolate(\n",
        "            mask.unsqueeze(0), (self.sz, self.sz),\n",
        "            mode='nearest').squeeze(0)\n",
        "        mask = (mask > 0.5).float()\n",
        "\n",
        "        if self.mode == 'train':\n",
        "            image, mask = self._augment_spatial(image, mask)\n",
        "            image = self._augment_intensity(image)\n",
        "\n",
        "        return {\n",
        "            \"image\": image,\n",
        "            \"mask\": mask,\n",
        "            \"subject_id\": e[\"subject_id\"],\n",
        "            \"site\": e[\"site\"],\n",
        "            \"slice_idx\": e[\"slice_idx\"],\n",
        "            \"has_lesion\": e[\"has_lesion\"],\n",
        "            \"les_frac\": e[\"les_frac\"],\n",
        "        }\n",
        "\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"Building datasets...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(\"\\nTrain:\")\n",
        "train_ds = WMHDatasetV2(train_subj, IMG_SIZE, 'train', BG_RATIO_TRAIN)\n",
        "print(\"\\nVal:\")\n",
        "val_ds = WMHDatasetV2(val_subj, IMG_SIZE, 'val', BG_RATIO_VAL)\n",
        "print(\"\\nTest:\")\n",
        "test_ds = WMHDatasetV2(test_subj, IMG_SIZE, 'test', BG_RATIO_VAL)\n",
        "\n",
        "train_loader = DataLoader(\n",
        "    train_ds, batch_size=BATCH_SIZE, shuffle=True,\n",
        "    num_workers=NUM_WORKERS, pin_memory=True, drop_last=True,\n",
        "    persistent_workers=True)\n",
        "val_loader = DataLoader(\n",
        "    val_ds, batch_size=BATCH_SIZE, shuffle=False,\n",
        "    num_workers=NUM_WORKERS, pin_memory=True,\n",
        "    persistent_workers=True)\n",
        "test_loader = DataLoader(\n",
        "    test_ds, batch_size=1, shuffle=False,\n",
        "    num_workers=NUM_WORKERS, pin_memory=True)\n",
        "\n",
        "s = train_ds[0]\n",
        "assert s['image'].shape == (1, IMG_SIZE, IMG_SIZE)\n",
        "print(f\"\\nâœ“ Dataset: image={s['image'].shape}, \"\n",
        "      f\"mask={s['mask'].shape}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# # 7. Model Architecture\n",
        "\n",
        "# %%\n",
        "class LoRALinear(nn.Module):\n",
        "    \"\"\"LoRA with optional dropout for regularization.\"\"\"\n",
        "    def __init__(self, orig, rank=4, alpha=1.0, dropout=0.05):\n",
        "        super().__init__()\n",
        "        self.in_f = orig.in_features\n",
        "        self.out_f = orig.out_features\n",
        "        self.scaling = alpha / rank\n",
        "        self.weight = orig.weight\n",
        "        self.weight.requires_grad = False\n",
        "        self.bias = orig.bias\n",
        "        if self.bias is not None:\n",
        "            self.bias.requires_grad = False\n",
        "        self.lora_A = nn.Parameter(torch.empty(rank, self.in_f))\n",
        "        self.lora_B = nn.Parameter(torch.empty(self.out_f, rank))\n",
        "        nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(5))\n",
        "        nn.init.zeros_(self.lora_B)\n",
        "        self.dropout = nn.Dropout(dropout) if dropout > 0 else None\n",
        "\n",
        "    def forward(self, x):\n",
        "        base = F.linear(x, self.weight, self.bias)\n",
        "        lora_in = self.dropout(x) if self.dropout else x\n",
        "        return base + F.linear(\n",
        "            F.linear(lora_in, self.lora_A),\n",
        "            self.lora_B) * self.scaling\n",
        "\n",
        "\n",
        "class MultiScaleDecoder(nn.Module):\n",
        "    \"\"\"\n",
        "    Multi-scale decoder with skip-like refinement.\n",
        "    Better than simple sequential upsampling for\n",
        "    small lesion boundaries.\n",
        "    \"\"\"\n",
        "    def __init__(self, in_ch=256):\n",
        "        super().__init__()\n",
        "        # Main upsampling path\n",
        "        self.up1 = self._up_block(in_ch, 128)\n",
        "        self.up2 = self._up_block(128, 64)\n",
        "        self.up3 = self._up_block(64, 32)\n",
        "        self.up4 = self._up_block(32, 16)\n",
        "\n",
        "        # Refinement convolutions after each upsample\n",
        "        self.ref1 = self._refine(128)\n",
        "        self.ref2 = self._refine(64)\n",
        "        self.ref3 = self._refine(32)\n",
        "\n",
        "        # Multi-scale prediction heads\n",
        "        self.head_32 = nn.Conv2d(128, 1, 1)   # 64Ã—64\n",
        "        self.head_64 = nn.Conv2d(64, 1, 1)    # 128Ã—128\n",
        "        self.head_128 = nn.Conv2d(32, 1, 1)   # 256Ã—256\n",
        "        self.head_final = nn.Conv2d(16, 1, 1)  # 512Ã—512\n",
        "\n",
        "        # Learned fusion of multi-scale predictions\n",
        "        self.fuse = nn.Sequential(\n",
        "            nn.Conv2d(4, 8, 3, padding=1),\n",
        "            nn.BatchNorm2d(8), nn.GELU(),\n",
        "            nn.Conv2d(8, 1, 1))\n",
        "\n",
        "    @staticmethod\n",
        "    def _up_block(ic, oc):\n",
        "        return nn.Sequential(\n",
        "            nn.ConvTranspose2d(ic, oc, 2, stride=2),\n",
        "            nn.BatchNorm2d(oc), nn.GELU(),\n",
        "            nn.Conv2d(oc, oc, 3, padding=1),\n",
        "            nn.BatchNorm2d(oc), nn.GELU())\n",
        "\n",
        "    @staticmethod\n",
        "    def _refine(ch):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(ch, ch, 3, padding=1),\n",
        "            nn.BatchNorm2d(ch), nn.GELU())\n",
        "\n",
        "    def forward(self, feat):\n",
        "        \"\"\"feat: [B, 256, 32, 32] â†’ [B, 1, 512, 512]\"\"\"\n",
        "        target_size = (512, 512)\n",
        "\n",
        "        x1 = self.up1(feat)      # [B, 128, 64, 64]\n",
        "        x1 = self.ref1(x1)\n",
        "        p1 = self.head_32(x1)     # [B, 1, 64, 64]\n",
        "\n",
        "        x2 = self.up2(x1)         # [B, 64, 128, 128]\n",
        "        x2 = self.ref2(x2)\n",
        "        p2 = self.head_64(x2)     # [B, 1, 128, 128]\n",
        "\n",
        "        x3 = self.up3(x2)         # [B, 32, 256, 256]\n",
        "        x3 = self.ref3(x3)\n",
        "        p3 = self.head_128(x3)    # [B, 1, 256, 256]\n",
        "\n",
        "        x4 = self.up4(x3)         # [B, 16, 512, 512]\n",
        "        p4 = self.head_final(x4)  # [B, 1, 512, 512]\n",
        "\n",
        "        # Upsample all to target\n",
        "        p1_up = F.interpolate(p1, target_size, mode='bilinear',\n",
        "                              align_corners=False)\n",
        "        p2_up = F.interpolate(p2, target_size, mode='bilinear',\n",
        "                              align_corners=False)\n",
        "        p3_up = F.interpolate(p3, target_size, mode='bilinear',\n",
        "                              align_corners=False)\n",
        "\n",
        "        fused = self.fuse(\n",
        "            torch.cat([p1_up, p2_up, p3_up, p4], dim=1))\n",
        "\n",
        "        return fused, [p1, p2, p3, p4]\n",
        "\n",
        "\n",
        "class MedSAMLoRAUltimate(nn.Module):\n",
        "    \"\"\"\n",
        "    Med-SAM ViT-B + High-rank LoRA + Multi-scale decoder.\n",
        "\n",
        "    Changes from V1:\n",
        "    - LoRA rank 32-64 (was 4)\n",
        "    - LoRA dropout for regularization\n",
        "    - LoRA on MLP layers in addition to attention\n",
        "    - Multi-scale decoder with deep supervision\n",
        "    - Channel adapter with learned mixing\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, ckpt, lora_rank=64, lora_alpha=64.0,\n",
        "                 lora_dropout=0.05, inject_proj=True,\n",
        "                 inject_mlp=True, grad_ckpt=False):\n",
        "        super().__init__()\n",
        "        self.use_gc = grad_ckpt\n",
        "\n",
        "        print(\"  Loading Med-SAM ViT-B...\")\n",
        "        sam = sam_model_registry[\"vit_b\"](checkpoint=ckpt)\n",
        "        self.image_encoder = sam.image_encoder\n",
        "        del sam.prompt_encoder, sam.mask_decoder, sam\n",
        "        gc.collect()\n",
        "        if torch.cuda.is_available():\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "        # Learned channel adapter (1â†’3)\n",
        "        self.channel_adapter = nn.Sequential(\n",
        "            nn.Conv2d(1, 16, 3, padding=1),\n",
        "            nn.BatchNorm2d(16), nn.GELU(),\n",
        "            nn.Conv2d(16, 3, 1))\n",
        "\n",
        "        # Initialize adapter near identity\n",
        "        with torch.no_grad():\n",
        "            nn.init.kaiming_normal_(\n",
        "                self.channel_adapter[0].weight)\n",
        "            self.channel_adapter[0].bias.zero_()\n",
        "            self.channel_adapter[3].weight.zero_()\n",
        "            for c in range(3):\n",
        "                # Each output channel averages from 16 intermediate\n",
        "                self.channel_adapter[3].weight[c, :, 0, 0] = 1/16\n",
        "            self.channel_adapter[3].bias.zero_()\n",
        "\n",
        "        # Freeze encoder\n",
        "        for p in self.image_encoder.parameters():\n",
        "            p.requires_grad = False\n",
        "\n",
        "        # Inject LoRA into attention AND MLP\n",
        "        self.lora_layers = nn.ModuleList()\n",
        "        n_attn = n_mlp = 0\n",
        "        for blk in self.image_encoder.blocks:\n",
        "            # QKV\n",
        "            if isinstance(blk.attn.qkv, nn.Linear):\n",
        "                l = LoRALinear(blk.attn.qkv, lora_rank,\n",
        "                               lora_alpha, lora_dropout)\n",
        "                blk.attn.qkv = l\n",
        "                self.lora_layers.append(l)\n",
        "                n_attn += 1\n",
        "\n",
        "            # Attention projection\n",
        "            if inject_proj and isinstance(\n",
        "                    blk.attn.proj, nn.Linear):\n",
        "                l = LoRALinear(blk.attn.proj, lora_rank,\n",
        "                               lora_alpha, lora_dropout)\n",
        "                blk.attn.proj = l\n",
        "                self.lora_layers.append(l)\n",
        "                n_attn += 1\n",
        "\n",
        "            # MLP layers (fc1, fc2)\n",
        "            if inject_mlp:\n",
        "                if hasattr(blk.mlp, 'lin1') and \\\n",
        "                   isinstance(blk.mlp.lin1, nn.Linear):\n",
        "                    l = LoRALinear(blk.mlp.lin1, lora_rank // 2,\n",
        "                                   lora_alpha / 2, lora_dropout)\n",
        "                    blk.mlp.lin1 = l\n",
        "                    self.lora_layers.append(l)\n",
        "                    n_mlp += 1\n",
        "                if hasattr(blk.mlp, 'lin2') and \\\n",
        "                   isinstance(blk.mlp.lin2, nn.Linear):\n",
        "                    l = LoRALinear(blk.mlp.lin2, lora_rank // 2,\n",
        "                                   lora_alpha / 2, lora_dropout)\n",
        "                    blk.mlp.lin2 = l\n",
        "                    self.lora_layers.append(l)\n",
        "                    n_mlp += 1\n",
        "\n",
        "        print(f\"  LoRA: {n_attn} attn + {n_mlp} MLP layers \"\n",
        "              f\"(rank={lora_rank})\")\n",
        "\n",
        "        # Multi-scale decoder\n",
        "        self.decoder = MultiScaleDecoder(256)\n",
        "\n",
        "        tot = sum(p.numel() for p in self.parameters())\n",
        "        trn = sum(p.numel() for p in self.parameters()\n",
        "                  if p.requires_grad)\n",
        "        lora_p = sum(p.numel()\n",
        "                     for p in self.lora_layers.parameters())\n",
        "        adapt_p = sum(p.numel()\n",
        "                      for p in self.channel_adapter.parameters())\n",
        "        dec_p = sum(p.numel()\n",
        "                    for p in self.decoder.parameters())\n",
        "\n",
        "        print(f\"\\n  {'='*50}\")\n",
        "        print(f\"  Adapter:   {adapt_p:>12,}\")\n",
        "        print(f\"  LoRA:      {lora_p:>12,}\")\n",
        "        print(f\"  Decoder:   {dec_p:>12,}\")\n",
        "        print(f\"  Frozen:    {tot-trn:>12,}\")\n",
        "        print(f\"  {'â”€'*36}\")\n",
        "        print(f\"  Total:     {tot:>12,}\")\n",
        "        print(f\"  Trainable: {trn:>12,} ({100*trn/tot:.2f}%)\")\n",
        "        print(f\"  {'='*50}\\n\")\n",
        "\n",
        "    def _interp_pos(self, x):\n",
        "        pos = self.image_encoder.pos_embed\n",
        "        _, H0, W0, C = pos.shape\n",
        "        _, H1, W1, _ = x.shape\n",
        "        if H1 == H0 and W1 == W0: return pos\n",
        "        p = pos.permute(0,3,1,2).float()\n",
        "        p = F.interpolate(p, (H1,W1), mode='bicubic',\n",
        "                          align_corners=False)\n",
        "        return p.permute(0,2,3,1)\n",
        "\n",
        "    def forward(self, x, return_multiscale=False):\n",
        "        \"\"\"\n",
        "        x: [B, 1, 512, 512]\n",
        "        Returns: logits [B, 1, 512, 512]\n",
        "        If return_multiscale: also returns list of\n",
        "        intermediate predictions for deep supervision\n",
        "        \"\"\"\n",
        "        x = self.channel_adapter(x)\n",
        "        enc = self.image_encoder\n",
        "        tokens = enc.patch_embed(x)\n",
        "        tokens = tokens + self._interp_pos(tokens)\n",
        "        for blk in enc.blocks:\n",
        "            if self.use_gc and self.training:\n",
        "                tokens = grad_checkpoint(\n",
        "                    blk, tokens, use_reentrant=False)\n",
        "            else:\n",
        "                tokens = blk(tokens)\n",
        "        feat = enc.neck(tokens.permute(0,3,1,2))\n",
        "        logits, multi = self.decoder(feat)\n",
        "\n",
        "        if return_multiscale:\n",
        "            return logits, multi\n",
        "        return logits\n",
        "\n",
        "    def get_trainable_params(self):\n",
        "        return [p for p in self.parameters() if p.requires_grad]\n",
        "\n",
        "    def save_checkpoint(self, path, epoch, optimizer, scheduler,\n",
        "                        scaler, best_dice, history):\n",
        "        \"\"\"Full checkpoint for resume.\"\"\"\n",
        "        trainable = {k: v.cpu() for k, v in self.named_parameters()\n",
        "                     if v.requires_grad}\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_trainable': trainable,\n",
        "            'optimizer': optimizer.state_dict(),\n",
        "            'scheduler': scheduler.state_dict(),\n",
        "            'scaler': scaler.state_dict(),\n",
        "            'best_dice': best_dice,\n",
        "            'history': history,\n",
        "        }, path)\n",
        "        print(f\"  Checkpoint: {path} \"\n",
        "              f\"({os.path.getsize(path)/1e6:.1f} MB)\")\n",
        "\n",
        "    def load_checkpoint(self, path, optimizer=None,\n",
        "                        scheduler=None, scaler=None):\n",
        "        \"\"\"Load checkpoint and optionally restore optimizer.\"\"\"\n",
        "        ckpt = torch.load(path, map_location='cpu',\n",
        "                          weights_only=False)\n",
        "        own = self.state_dict()\n",
        "        n = 0\n",
        "        for k, v in ckpt['model_trainable'].items():\n",
        "            if k in own:\n",
        "                own[k].copy_(v)\n",
        "                n += 1\n",
        "        print(f\"  Loaded {n} tensors from epoch \"\n",
        "              f\"{ckpt['epoch']}\")\n",
        "        if optimizer and 'optimizer' in ckpt:\n",
        "            optimizer.load_state_dict(ckpt['optimizer'])\n",
        "        if scheduler and 'scheduler' in ckpt:\n",
        "            scheduler.load_state_dict(ckpt['scheduler'])\n",
        "        if scaler and 'scaler' in ckpt:\n",
        "            scaler.load_state_dict(ckpt['scaler'])\n",
        "        return (ckpt['epoch'],\n",
        "                ckpt.get('best_dice', 0),\n",
        "                ckpt.get('history', {\n",
        "                    'tl':[],'vl':[],'vd':[],'lr':[]}))\n",
        "\n",
        "    def save_weights_only(self, path):\n",
        "        \"\"\"Lightweight save of just trainable params.\"\"\"\n",
        "        st = {k: v.cpu() for k, v in self.named_parameters()\n",
        "              if v.requires_grad}\n",
        "        torch.save(st, path)\n",
        "\n",
        "    def load_weights_only(self, path):\n",
        "        st = torch.load(path, map_location='cpu',\n",
        "                        weights_only=True)\n",
        "        own = self.state_dict()\n",
        "        n = 0\n",
        "        for k, v in st.items():\n",
        "            if k in own: own[k].copy_(v); n += 1\n",
        "        print(f\"  Loaded {n} weight tensors\")\n",
        "\n",
        "\n",
        "# Build model\n",
        "print(\"=\"*60)\n",
        "print(\"Building model...\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "model = MedSAMLoRAUltimate(\n",
        "    ckpt=MEDSAM_CHECKPOINT,\n",
        "    lora_rank=LORA_RANK,\n",
        "    lora_alpha=LORA_ALPHA,\n",
        "    lora_dropout=0.05,\n",
        "    inject_proj=True,\n",
        "    inject_mlp=True,\n",
        "    grad_ckpt=GRAD_CKPT,\n",
        ").to(device)\n",
        "\n",
        "# Forward test\n",
        "print(\"Forward pass test...\")\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    d_in = torch.randn(1, 1, IMG_SIZE, IMG_SIZE, device=device)\n",
        "    if device.type == 'cuda':\n",
        "        with torch.amp.autocast('cuda'):\n",
        "            d_out, d_multi = model(d_in, return_multiscale=True)\n",
        "    else:\n",
        "        d_out, d_multi = model(d_in, return_multiscale=True)\n",
        "    assert d_out.shape == (1, 1, IMG_SIZE, IMG_SIZE)\n",
        "    print(f\"  Main:   {d_out.shape}\")\n",
        "    for i, p in enumerate(d_multi):\n",
        "        print(f\"  Scale {i}: {p.shape}\")\n",
        "    del d_in, d_out, d_multi\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "print(\"âœ“ Model verified\\n\")\n",
        "\n",
        "# %% [markdown]\n",
        "# # 8. Advanced Loss Function\n",
        "\n",
        "# %%\n",
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, alpha=0.75, gamma=2.0):\n",
        "        super().__init__()\n",
        "        self.a, self.g = alpha, gamma\n",
        "\n",
        "    def forward(self, lo, ta):\n",
        "        bce = F.binary_cross_entropy_with_logits(\n",
        "            lo, ta, reduction='none')\n",
        "        p = torch.sigmoid(lo)\n",
        "        pt = p * ta + (1-p) * (1-ta)\n",
        "        at = self.a * ta + (1-self.a) * (1-ta)\n",
        "        return (at * (1-pt)**self.g * bce).mean()\n",
        "\n",
        "\n",
        "class SoftDiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1.0):\n",
        "        super().__init__()\n",
        "        self.s = smooth\n",
        "\n",
        "    def forward(self, lo, ta):\n",
        "        p = torch.sigmoid(lo).view(lo.size(0), -1)\n",
        "        t = ta.view(ta.size(0), -1)\n",
        "        i = (p * t).sum(1)\n",
        "        return 1 - ((2*i+self.s) /\n",
        "                     (p.sum(1)+t.sum(1)+self.s)).mean()\n",
        "\n",
        "\n",
        "class BoundaryLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Loss that penalizes boundary errors more heavily.\n",
        "    Computed via distance-weighted BCE on the boundary region.\n",
        "    \"\"\"\n",
        "    def __init__(self, weight=1.0, kernel_size=5):\n",
        "        super().__init__()\n",
        "        self.weight = weight\n",
        "        self.ks = kernel_size\n",
        "\n",
        "    def forward(self, lo, ta):\n",
        "        # Find boundary pixels via dilation - erosion\n",
        "        pad = self.ks // 2\n",
        "        kernel = torch.ones(1, 1, self.ks, self.ks,\n",
        "                            device=ta.device)\n",
        "        dilated = F.conv2d(ta, kernel, padding=pad).clamp(0, 1)\n",
        "        eroded = 1 - F.conv2d(1 - ta, kernel,\n",
        "                               padding=pad).clamp(0, 1)\n",
        "        boundary = (dilated - eroded).clamp(0, 1)\n",
        "\n",
        "        # Boundary-weighted BCE\n",
        "        bce = F.binary_cross_entropy_with_logits(\n",
        "            lo, ta, reduction='none')\n",
        "        # Weight boundary pixels 3Ã— more\n",
        "        weight_map = 1.0 + 2.0 * boundary\n",
        "        return (weight_map * bce).mean() * self.weight\n",
        "\n",
        "\n",
        "class DeepSupervisionLoss(nn.Module):\n",
        "    \"\"\"\n",
        "    Combined loss with deep supervision from multi-scale decoder.\n",
        "\n",
        "    Main output:    Focal + Dice + Boundary\n",
        "    Aux outputs:    Focal + Dice (downsampled GT)\n",
        "\n",
        "    Weights: main=1.0, aux=[0.4, 0.3, 0.2, 0.1]\n",
        "    \"\"\"\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.focal = FocalLoss(alpha=0.75, gamma=2.0)\n",
        "        self.dice = SoftDiceLoss(smooth=1.0)\n",
        "        self.boundary = BoundaryLoss(weight=0.5)\n",
        "\n",
        "        # Aux weights: 64Ã—64, 128Ã—128, 256Ã—256, 512Ã—512\n",
        "        self.aux_weights = [0.4, 0.3, 0.2, 0.1]\n",
        "\n",
        "    def forward(self, main_logits, multi_logits, target):\n",
        "        \"\"\"\n",
        "        main_logits: [B, 1, 512, 512]\n",
        "        multi_logits: list of [B, 1, H, W] at different scales\n",
        "        target: [B, 1, 512, 512]\n",
        "        \"\"\"\n",
        "        # Main loss\n",
        "        loss = (self.focal(main_logits, target) +\n",
        "                self.dice(main_logits, target) +\n",
        "                self.boundary(main_logits, target))\n",
        "\n",
        "        # Deep supervision\n",
        "        for i, (aux, w) in enumerate(\n",
        "                zip(multi_logits, self.aux_weights)):\n",
        "            h, w_px = aux.shape[-2:]\n",
        "            t_down = F.interpolate(target, (h, w_px),\n",
        "                                   mode='nearest')\n",
        "            aux_loss = (self.focal(aux, t_down) +\n",
        "                        self.dice(aux, t_down))\n",
        "            loss = loss + w * aux_loss\n",
        "\n",
        "        return loss\n",
        "\n",
        "# %% [markdown]\n",
        "# # 9. Trainer with Cosine Warm Restarts + Auto Checkpoint\n",
        "\n",
        "# %%\n",
        "class UltimateTrainer:\n",
        "    def __init__(self, model, device, lr=3e-4, wd=0.01,\n",
        "                 accum=4, warmup=5, restart_period=25,\n",
        "                 ckpt_every=10, backup_dir=BACKUP_DIR):\n",
        "        self.model = model\n",
        "        self.dev = device\n",
        "        self.accum = accum\n",
        "        self.warmup = warmup\n",
        "        self.backup_dir = backup_dir\n",
        "        self.ckpt_every = ckpt_every\n",
        "\n",
        "        self.criterion = DeepSupervisionLoss()\n",
        "\n",
        "        self.opt = torch.optim.AdamW(\n",
        "            model.get_trainable_params(),\n",
        "            lr=lr, weight_decay=wd, betas=(0.9, 0.999))\n",
        "\n",
        "        # CosineAnnealingWarmRestarts\n",
        "        self.scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
        "            self.opt, T_0=restart_period, T_mult=1, eta_min=1e-6)\n",
        "\n",
        "        self.scaler = torch.amp.GradScaler('cuda')\n",
        "        self.dm = monai.metrics.DiceMetric(\n",
        "            include_background=False, reduction=\"mean\")\n",
        "\n",
        "        self.hist = {'tl': [], 'vl': [], 'vd': [], 'lr': []}\n",
        "        self.best = 0.0\n",
        "        self.start_epoch = 0\n",
        "\n",
        "    def resume(self, ckpt_path):\n",
        "        \"\"\"Resume from checkpoint.\"\"\"\n",
        "        ep, best, hist = self.model.load_checkpoint(\n",
        "            ckpt_path, self.opt, self.scheduler, self.scaler)\n",
        "        self.start_epoch = ep\n",
        "        self.best = best\n",
        "        self.hist = hist\n",
        "        # Advance scheduler to correct position\n",
        "        for _ in range(ep):\n",
        "            self.scheduler.step()\n",
        "        print(f\"  Resuming from epoch {ep}, best={best:.4f}\")\n",
        "\n",
        "    def _warmup_lr(self, ep):\n",
        "        \"\"\"Manual warmup before handing off to scheduler.\"\"\"\n",
        "        if ep < self.warmup:\n",
        "            factor = (ep + 1) / self.warmup\n",
        "            for pg in self.opt.param_groups:\n",
        "                pg['lr'] = pg['initial_lr'] * factor \\\n",
        "                    if 'initial_lr' in pg else 3e-4 * factor\n",
        "\n",
        "    def train_epoch(self, loader, epoch):\n",
        "        self.model.train()\n",
        "        total_loss = 0\n",
        "        n_steps = 0\n",
        "\n",
        "        if epoch < self.warmup:\n",
        "            self._warmup_lr(epoch)\n",
        "\n",
        "        self.opt.zero_grad(set_to_none=True)\n",
        "\n",
        "        for step, batch in enumerate(loader):\n",
        "            im = batch['image'].to(self.dev, non_blocking=True)\n",
        "            mk = batch['mask'].to(self.dev, non_blocking=True)\n",
        "\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                main_out, multi_out = self.model(\n",
        "                    im, return_multiscale=True)\n",
        "                loss = self.criterion(\n",
        "                    main_out, multi_out, mk) / self.accum\n",
        "\n",
        "            self.scaler.scale(loss).backward()\n",
        "\n",
        "            if (step + 1) % self.accum == 0:\n",
        "                self.scaler.unscale_(self.opt)\n",
        "                nn.utils.clip_grad_norm_(\n",
        "                    self.model.get_trainable_params(), 1.0)\n",
        "                self.scaler.step(self.opt)\n",
        "                self.scaler.update()\n",
        "                self.opt.zero_grad(set_to_none=True)\n",
        "\n",
        "            total_loss += loss.item() * self.accum\n",
        "            n_steps += 1\n",
        "            del im, mk, main_out, multi_out, loss\n",
        "\n",
        "        # Flush remaining gradients\n",
        "        if n_steps % self.accum != 0:\n",
        "            self.scaler.unscale_(self.opt)\n",
        "            nn.utils.clip_grad_norm_(\n",
        "                self.model.get_trainable_params(), 1.0)\n",
        "            self.scaler.step(self.opt)\n",
        "            self.scaler.update()\n",
        "            self.opt.zero_grad(set_to_none=True)\n",
        "\n",
        "        # Step scheduler (after warmup)\n",
        "        if epoch >= self.warmup:\n",
        "            self.scheduler.step()\n",
        "\n",
        "        lr = self.opt.param_groups[0]['lr']\n",
        "        return total_loss / max(n_steps, 1), lr\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def val_epoch(self, loader):\n",
        "        self.model.eval()\n",
        "        total_loss = 0\n",
        "        n_steps = 0\n",
        "        self.dm.reset()\n",
        "        stp = defaultdict(float)\n",
        "        sfp = defaultdict(float)\n",
        "        sfn = defaultdict(float)\n",
        "\n",
        "        for batch in loader:\n",
        "            im = batch['image'].to(self.dev, non_blocking=True)\n",
        "            mk = batch['mask'].to(self.dev, non_blocking=True)\n",
        "\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                main_out, multi_out = self.model(\n",
        "                    im, return_multiscale=True)\n",
        "                loss = self.criterion(main_out, multi_out, mk)\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            n_steps += 1\n",
        "\n",
        "            pred = (torch.sigmoid(main_out) > 0.5).float()\n",
        "            self.dm(pred, mk.long())\n",
        "\n",
        "            pn = pred.cpu().numpy()\n",
        "            mn = mk.cpu().numpy()\n",
        "            for i, s in enumerate(batch['site']):\n",
        "                p = pn[i].flatten()\n",
        "                m = mn[i].flatten()\n",
        "                stp[s] += (p * m).sum()\n",
        "                sfp[s] += (p * (1-m)).sum()\n",
        "                sfn[s] += ((1-p) * m).sum()\n",
        "\n",
        "            del im, mk, main_out, multi_out, loss, pred\n",
        "\n",
        "        dice = self.dm.aggregate().item()\n",
        "        self.dm.reset()\n",
        "        sd = {s: (2*stp[s]+1)/(2*stp[s]+sfp[s]+sfn[s]+1)\n",
        "              for s in stp}\n",
        "        return total_loss / max(n_steps, 1), dice, sd\n",
        "\n",
        "    def train(self, train_ld, val_ld, epochs=100):\n",
        "        eff = train_ld.batch_size * self.accum\n",
        "        print(f\"\\n{'='*70}\")\n",
        "        print(f\"  Ultimate Training\")\n",
        "        print(f\"  {epochs} epochs | eff_batch={eff} | \"\n",
        "              f\"LoRA rank={LORA_RANK}\")\n",
        "        print(f\"  Train:{len(train_ld.dataset)} \"\n",
        "              f\"Val:{len(val_ld.dataset)}\")\n",
        "        print(f\"  Checkpoint every {self.ckpt_every} epochs \"\n",
        "              f\"â†’ {self.backup_dir}\")\n",
        "        print(f\"{'='*70}\\n\")\n",
        "\n",
        "        start_ep = self.start_epoch\n",
        "        epoch_times = []\n",
        "\n",
        "        for ep in range(start_ep, epochs):\n",
        "            t0 = time.time()\n",
        "\n",
        "            tl, lr = self.train_epoch(train_ld, ep)\n",
        "            vl, vd, sd = self.val_epoch(val_ld)\n",
        "\n",
        "            self.hist['tl'].append(tl)\n",
        "            self.hist['vl'].append(vl)\n",
        "            self.hist['vd'].append(vd)\n",
        "            self.hist['lr'].append(lr)\n",
        "\n",
        "            elapsed = time.time() - t0\n",
        "            epoch_times.append(elapsed)\n",
        "\n",
        "            mk = \"\"\n",
        "            if vd > self.best:\n",
        "                self.best = vd\n",
        "                self.model.save_weights_only(\n",
        "                    f\"{self.backup_dir}/best_ultimate.pth\")\n",
        "                self.model.save_weights_only(\n",
        "                    \"/content/best_ultimate.pth\")\n",
        "                mk = \" â˜…\"\n",
        "\n",
        "            mem = (torch.cuda.max_memory_allocated()/1e9\n",
        "                   if torch.cuda.is_available() else 0)\n",
        "            ss = \" | \".join(f\"{s[:3]}:{d:.3f}\"\n",
        "                            for s, d in sorted(sd.items()))\n",
        "            eta = np.mean(epoch_times[-10:]) * (epochs - ep - 1)\n",
        "            eta_str = (f\"{eta/3600:.1f}h\" if eta > 3600\n",
        "                       else f\"{eta/60:.0f}m\")\n",
        "\n",
        "            print(f\"E{ep+1:3d}/{epochs} â”‚ \"\n",
        "                  f\"LR {lr:.2e} â”‚ \"\n",
        "                  f\"Tr {tl:.4f} â”‚ Vl {vl:.4f} â”‚ \"\n",
        "                  f\"Dice {vd:.4f} â”‚ {ss} â”‚ \"\n",
        "                  f\"{mem:.1f}G â”‚ {elapsed:.0f}s â”‚ \"\n",
        "                  f\"ETA {eta_str}{mk}\")\n",
        "\n",
        "            # Periodic checkpoint to Drive\n",
        "            if (ep + 1) % self.ckpt_every == 0:\n",
        "                ckpt_path = (f\"{self.backup_dir}/\"\n",
        "                             f\"checkpoint_ep{ep+1:03d}.pth\")\n",
        "                self.model.save_checkpoint(\n",
        "                    ckpt_path, ep + 1, self.opt,\n",
        "                    self.scheduler, self.scaler,\n",
        "                    self.best, self.hist)\n",
        "\n",
        "                # Save history for plotting\n",
        "                with open(f\"{self.backup_dir}/\"\n",
        "                          f\"history.json\", \"w\") as f:\n",
        "                    json.dump(\n",
        "                        {k: [float(v) for v in vals]\n",
        "                         for k, vals in self.hist.items()},\n",
        "                        f, indent=2)\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                torch.cuda.empty_cache()\n",
        "                torch.cuda.reset_peak_memory_stats()\n",
        "\n",
        "        print(f\"\\n{'='*60}\")\n",
        "        print(f\"  Training complete. Best Dice: {self.best:.4f}\")\n",
        "        print(f\"{'='*60}\")\n",
        "        return self.hist\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def test(self, loader):\n",
        "        self.model.eval()\n",
        "        self.dm.reset()\n",
        "        atp = afp = afn = 0\n",
        "        stp = defaultdict(float)\n",
        "        sfp = defaultdict(float)\n",
        "        sfn = defaultdict(float)\n",
        "        for b in loader:\n",
        "            im = b['image'].to(self.dev, non_blocking=True)\n",
        "            mk = b['mask'].to(self.dev, non_blocking=True)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                o = self.model(im)\n",
        "            pr = (torch.sigmoid(o) > 0.5).float()\n",
        "            self.dm(pr, mk.long())\n",
        "            pn = pr.cpu().numpy()\n",
        "            mn = mk.cpu().numpy()\n",
        "            for i, s in enumerate(b['site']):\n",
        "                p = pn[i].flatten()\n",
        "                m = mn[i].flatten()\n",
        "                tp = (p*m).sum()\n",
        "                fp = (p*(1-m)).sum()\n",
        "                fn = ((1-p)*m).sum()\n",
        "                stp[s] += tp; sfp[s] += fp; sfn[s] += fn\n",
        "                atp += tp; afp += fp; afn += fn\n",
        "            del im, mk, o, pr\n",
        "        d = self.dm.aggregate().item()\n",
        "        self.dm.reset()\n",
        "        pr_ = atp / max(atp+afp, 1)\n",
        "        re_ = atp / max(atp+afn, 1)\n",
        "        f1 = 2*pr_*re_ / max(pr_+re_, 1e-8)\n",
        "        print(f\"\\n  TEST: Dice={d:.4f} P={pr_:.4f} \"\n",
        "              f\"R={re_:.4f} F1={f1:.4f}\")\n",
        "        for s in sorted(stp):\n",
        "            dd = (2*stp[s]+1)/(2*stp[s]+sfp[s]+sfn[s]+1)\n",
        "            print(f\"    {s:12s}: {dd:.4f}\")\n",
        "        return {'dice':d, 'precision':pr_, 'recall':re_, 'f1':f1}\n",
        "\n",
        "\n",
        "# Build trainer\n",
        "trainer = UltimateTrainer(\n",
        "    model, device,\n",
        "    lr=BASE_LR, wd=WEIGHT_DECAY,\n",
        "    accum=ACCUM_STEPS,\n",
        "    warmup=WARMUP_EPOCHS,\n",
        "    restart_period=RESTART_PERIOD,\n",
        "    ckpt_every=CHECKPOINT_EVERY,\n",
        "    backup_dir=BACKUP_DIR,\n",
        ")\n",
        "\n",
        "# Resume if checkpoint found\n",
        "if RESUME_CKPT:\n",
        "    trainer.resume(RESUME_CKPT)\n",
        "\n",
        "print(\"âœ“ Trainer ready\\n\")\n",
        "\n",
        "# %% [markdown]\n",
        "# # 10. Train\n",
        "\n",
        "# %%\n",
        "history = trainer.train(train_loader, val_loader, epochs=EPOCHS)\n",
        "\n",
        "# Load best weights\n",
        "model.load_weights_only(f\"{BACKUP_DIR}/best_ultimate.pth\")\n",
        "model.eval()\n",
        "\n",
        "# Baseline test\n",
        "print(\"\\nBaseline test (thr=0.5, no post-processing):\")\n",
        "baseline = trainer.test(test_loader)\n",
        "\n",
        "# %% [markdown]\n",
        "# # 11. Training Curves\n",
        "\n",
        "# %%\n",
        "def plot_history(h):\n",
        "    fig, axes = plt.subplots(1, 3, figsize=(20, 6))\n",
        "\n",
        "    axes[0].plot(h['tl'], label='Train', lw=2, alpha=0.8)\n",
        "    axes[0].plot(h['vl'], label='Val', lw=2, alpha=0.8)\n",
        "    axes[0].set_xlabel('Epoch'); axes[0].set_ylabel('Loss')\n",
        "    axes[0].set_title('Loss (Focal+Dice+Boundary+DeepSup)')\n",
        "    axes[0].legend(); axes[0].grid(alpha=0.3)\n",
        "\n",
        "    axes[1].plot(h['vd'], color='green', lw=2)\n",
        "    best_ep = np.argmax(h['vd'])\n",
        "    axes[1].axvline(best_ep, color='green', ls='--', alpha=0.3)\n",
        "    axes[1].scatter([best_ep], [h['vd'][best_ep]],\n",
        "                    c='green', s=100, zorder=5, marker='*')\n",
        "    axes[1].set_xlabel('Epoch'); axes[1].set_ylabel('Dice')\n",
        "    axes[1].set_title(f\"Val Dice (best={max(h['vd']):.4f} \"\n",
        "                      f\"@ ep{best_ep+1})\")\n",
        "    axes[1].grid(alpha=0.3)\n",
        "\n",
        "    axes[2].plot(h['lr'], color='darkorange', lw=2)\n",
        "    axes[2].set_xlabel('Epoch'); axes[2].set_ylabel('LR')\n",
        "    axes[2].set_title('LR (CosineWarmRestarts)')\n",
        "    axes[2].set_yscale('log')\n",
        "    axes[2].grid(alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{BACKUP_DIR}/training_curves.png\", dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "plot_history(history)\n",
        "\n",
        "# %% [markdown]\n",
        "# # 12. Inference Engine\n",
        "\n",
        "# %%\n",
        "class WMHInferenceEngine:\n",
        "    def __init__(self, model, device, img_size=512):\n",
        "        self.model = model\n",
        "        self.device = device\n",
        "        self.img_size = img_size\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def predict_slice_probs(self, image_tensor, use_tta=False):\n",
        "        self.model.eval()\n",
        "        if not use_tta:\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                logits = self.model(image_tensor)\n",
        "                prob = torch.sigmoid(logits[0,0]).float()\n",
        "            return prob.cpu().numpy()\n",
        "\n",
        "        augments = [\n",
        "            lambda x: x,\n",
        "            lambda x: torch.flip(x, [-1]),\n",
        "            lambda x: torch.flip(x, [-2]),\n",
        "            lambda x: torch.flip(x, [-1, -2]),\n",
        "            # Add 90Â° rotations for 8-fold TTA\n",
        "            lambda x: torch.rot90(x, 1, [-2, -1]),\n",
        "            lambda x: torch.rot90(x, 2, [-2, -1]),\n",
        "            lambda x: torch.rot90(x, 3, [-2, -1]),\n",
        "            lambda x: torch.flip(torch.rot90(x, 1, [-2,-1]),\n",
        "                                 [-1]),\n",
        "        ]\n",
        "        deaugments = [\n",
        "            lambda x: x,\n",
        "            lambda x: torch.flip(x, [-1]),\n",
        "            lambda x: torch.flip(x, [-2]),\n",
        "            lambda x: torch.flip(x, [-1, -2]),\n",
        "            lambda x: torch.rot90(x, -1, [-2, -1]),\n",
        "            lambda x: torch.rot90(x, -2, [-2, -1]),\n",
        "            lambda x: torch.rot90(x, -3, [-2, -1]),\n",
        "            lambda x: torch.rot90(\n",
        "                torch.flip(x, [-1]), -1, [-2, -1]),\n",
        "        ]\n",
        "\n",
        "        probs = []\n",
        "        for aug, deaug in zip(augments, deaugments):\n",
        "            inp = aug(image_tensor)\n",
        "            with torch.amp.autocast('cuda'):\n",
        "                logits = self.model(inp)\n",
        "                prob = torch.sigmoid(logits[0,0]).float()\n",
        "            prob = deaug(prob.unsqueeze(0).unsqueeze(0))[0,0]\n",
        "            probs.append(prob)\n",
        "        return torch.stack(probs, 0).mean(0).cpu().numpy()\n",
        "\n",
        "    def predict_volume_probs(self, flair_path, use_tta=False):\n",
        "        nii = nib.load(flair_path)\n",
        "        fv = nii.get_fdata().astype(np.float32)\n",
        "        m = fv > 0\n",
        "        if m.sum() > 0:\n",
        "            v = fv[m]\n",
        "            lo, hi = np.percentile(v, [0.5, 99.5])\n",
        "            fv = np.clip(fv, lo, hi)\n",
        "            v = fv[m]\n",
        "            fv = (fv - v.mean()) / (max(v.std(), 1e-8))\n",
        "            fv[~m] = 0\n",
        "        H, W, D = fv.shape\n",
        "        pvol = np.zeros((H,W,D), np.float32)\n",
        "        for z in range(D):\n",
        "            img = torch.from_numpy(\n",
        "                fv[:,:,z]).float().unsqueeze(0).unsqueeze(0)\n",
        "            img = F.interpolate(\n",
        "                img, (self.img_size, self.img_size),\n",
        "                mode='bilinear', align_corners=False\n",
        "            ).to(self.device)\n",
        "            ps = self.predict_slice_probs(img, use_tta)\n",
        "            pt = torch.from_numpy(ps).float()\n",
        "            pt = F.interpolate(\n",
        "                pt.unsqueeze(0).unsqueeze(0), (H, W),\n",
        "                mode='bilinear', align_corners=False\n",
        "            )[0,0].numpy()\n",
        "            pvol[:,:,z] = pt\n",
        "            del img\n",
        "        return pvol, nii\n",
        "\n",
        "    @staticmethod\n",
        "    def apply_threshold(pv, thr):\n",
        "        return (pv > thr).astype(np.float32)\n",
        "\n",
        "    @staticmethod\n",
        "    def cc_filter(bv, min_v=3, max_v=None):\n",
        "        if bv.sum() == 0: return bv\n",
        "        struct = generate_binary_structure(3, 3)\n",
        "        lab, nc = scipy_label(bv, structure=struct)\n",
        "        out = np.zeros_like(bv)\n",
        "        for i in range(1, nc+1):\n",
        "            c = lab == i\n",
        "            s = c.sum()\n",
        "            if s < min_v: continue\n",
        "            if max_v and s > max_v: continue\n",
        "            out[c] = 1.0\n",
        "        return out\n",
        "\n",
        "    @staticmethod\n",
        "    def compute_metrics(pred, gt):\n",
        "        pf, gf = pred.flatten(), gt.flatten()\n",
        "        tp = (pf * gf).sum()\n",
        "        fp = (pf * (1-gf)).sum()\n",
        "        fn = ((1-pf) * gf).sum()\n",
        "        return {\n",
        "            'dice': (2*tp+1)/(2*tp+fp+fn+1),\n",
        "            'precision': tp/max(tp+fp, 1),\n",
        "            'recall': tp/max(tp+fn, 1),\n",
        "            'f1': 2*tp/max(2*tp+fp+fn, 1),\n",
        "            'pred_voxels': pf.sum(),\n",
        "            'gt_voxels': gf.sum(),\n",
        "        }\n",
        "\n",
        "\n",
        "engine = WMHInferenceEngine(model, device, IMG_SIZE)\n",
        "\n",
        "# %% [markdown]\n",
        "# # 13. Post-Training Optimization\n",
        "\n",
        "# %%\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "# Threshold Sweep\n",
        "# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
        "def threshold_sweep(engine, subjects, thresholds=None,\n",
        "                    use_tta=False, min_cc=3):\n",
        "    if thresholds is None:\n",
        "        thresholds = np.arange(0.10, 0.91, 0.05)\n",
        "\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"  Threshold Sweep â€” {len(subjects)} subjects \"\n",
        "          f\"({'TTA' if use_tta else 'no TTA'})\")\n",
        "    print(f\"{'='*60}\\n\")\n",
        "\n",
        "    pvols, gvols = [], []\n",
        "    for i, s in enumerate(subjects):\n",
        "        t0 = time.time()\n",
        "        pv, _ = engine.predict_volume_probs(\n",
        "            s['flair'], use_tta=use_tta)\n",
        "        gt = (nib.load(s['mask']).get_fdata() == 1\n",
        "              ).astype(np.float32)\n",
        "        pvols.append(pv); gvols.append(gt)\n",
        "        print(f\"  [{i+1}/{len(subjects)}] {s['subject_id']} \"\n",
        "              f\"({time.time()-t0:.1f}s)\")\n",
        "\n",
        "    print(f\"\\nSweeping {len(thresholds)} thresholds...\")\n",
        "    raw_res, filt_res = [], []\n",
        "    for thr in thresholds:\n",
        "        rd, fd = [], []\n",
        "        for pv, gt in zip(pvols, gvols):\n",
        "            pred = (pv > thr).astype(np.float32)\n",
        "            rd.append(engine.compute_metrics(pred, gt)['dice'])\n",
        "            pf = engine.cc_filter(pred, min_cc)\n",
        "            fd.append(engine.compute_metrics(pf, gt)['dice'])\n",
        "        raw_res.append({'thr': thr, 'mean': np.mean(rd),\n",
        "                        'std': np.std(rd)})\n",
        "        filt_res.append({'thr': thr, 'mean': np.mean(fd),\n",
        "                         'std': np.std(fd)})\n",
        "        print(f\"  thr={thr:.2f} â”‚ Raw:{np.mean(rd):.4f} â”‚ \"\n",
        "              f\"Filt:{np.mean(fd):.4f}\")\n",
        "\n",
        "    br = max(raw_res, key=lambda x: x['mean'])\n",
        "    bf = max(filt_res, key=lambda x: x['mean'])\n",
        "    print(f\"\\n  Best raw:  {br['thr']:.2f} â†’ {br['mean']:.4f}\")\n",
        "    print(f\"  Best filt: {bf['thr']:.2f} â†’ {bf['mean']:.4f}\")\n",
        "\n",
        "    return {'raw': raw_res, 'filt': filt_res,\n",
        "            'best_raw': br, 'best_filt': bf,\n",
        "            'pvols': pvols, 'gvols': gvols}\n",
        "\n",
        "\n",
        "# Run sweep without TTA\n",
        "sweep = threshold_sweep(engine, val_subj, use_tta=False, min_cc=3)\n",
        "\n",
        "# CC size optimization\n",
        "opt_thr = sweep['best_filt']['thr']\n",
        "print(f\"\\nCC size sweep at thr={opt_thr:.2f}:\")\n",
        "cc_sizes = [1, 2, 3, 5, 8, 10, 15, 20, 30]\n",
        "best_cc, best_cc_d = 3, 0\n",
        "for ms in cc_sizes:\n",
        "    dices = []\n",
        "    for pv, gt in zip(sweep['pvols'], sweep['gvols']):\n",
        "        pred = engine.cc_filter(\n",
        "            (pv > opt_thr).astype(np.float32), ms)\n",
        "        dices.append(engine.compute_metrics(pred, gt)['dice'])\n",
        "    md = np.mean(dices)\n",
        "    mk = \" â˜…\" if md > best_cc_d else \"\"\n",
        "    if md > best_cc_d: best_cc_d = md; best_cc = ms\n",
        "    print(f\"  CCâ‰¥{ms:3d} â†’ {md:.4f}{mk}\")\n",
        "print(f\"  Optimal: CCâ‰¥{best_cc}\")\n",
        "\n",
        "# TTA evaluation\n",
        "print(f\"\\nTTA impact check:\")\n",
        "tta_dices, no_tta_dices = [], []\n",
        "for i, s in enumerate(val_subj):\n",
        "    gt = (nib.load(s['mask']).get_fdata() == 1\n",
        "          ).astype(np.float32)\n",
        "    pv_no = sweep['pvols'][i]\n",
        "    d_no = engine.compute_metrics(\n",
        "        engine.cc_filter(\n",
        "            (pv_no > opt_thr).astype(np.float32), best_cc),\n",
        "        gt)['dice']\n",
        "    no_tta_dices.append(d_no)\n",
        "\n",
        "    pv_tta, _ = engine.predict_volume_probs(\n",
        "        s['flair'], use_tta=True)\n",
        "    d_tta = engine.compute_metrics(\n",
        "        engine.cc_filter(\n",
        "            (pv_tta > opt_thr).astype(np.float32), best_cc),\n",
        "        gt)['dice']\n",
        "    tta_dices.append(d_tta)\n",
        "    print(f\"  {s['subject_id']:20s} â”‚ \"\n",
        "          f\"NoTTA:{d_no:.4f} TTA:{d_tta:.4f}\")\n",
        "\n",
        "USE_TTA = np.mean(tta_dices) > np.mean(no_tta_dices)\n",
        "print(f\"\\n  NoTTA: {np.mean(no_tta_dices):.4f} | \"\n",
        "      f\"TTA: {np.mean(tta_dices):.4f}\")\n",
        "print(f\"  â†’ {'USE TTA' if USE_TTA else 'SKIP TTA'}\")\n",
        "\n",
        "# Re-sweep with TTA if beneficial\n",
        "if USE_TTA:\n",
        "    sweep_final = threshold_sweep(\n",
        "        engine, val_subj, use_tta=True, min_cc=best_cc)\n",
        "    OPT_THR = sweep_final['best_filt']['thr']\n",
        "else:\n",
        "    OPT_THR = opt_thr\n",
        "\n",
        "print(f\"\\nFinal: thr={OPT_THR:.2f}, CCâ‰¥{best_cc}, \"\n",
        "      f\"TTA={'ON' if USE_TTA else 'OFF'}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# # 14. Final Test Evaluation\n",
        "\n",
        "# %%\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"  FINAL TEST (thr={OPT_THR:.2f}, CCâ‰¥{best_cc}, \"\n",
        "      f\"TTA={'ON' if USE_TTA else 'OFF'})\")\n",
        "print(f\"{'='*70}\\n\")\n",
        "\n",
        "test_results = []\n",
        "site_m = defaultdict(list)\n",
        "\n",
        "for i, s in enumerate(test_subj):\n",
        "    gt = (nib.load(s['mask']).get_fdata() == 1\n",
        "          ).astype(np.float32)\n",
        "    pv, nii = engine.predict_volume_probs(\n",
        "        s['flair'], use_tta=USE_TTA)\n",
        "    pred = engine.cc_filter(\n",
        "        engine.apply_threshold(pv, OPT_THR), best_cc)\n",
        "    m = engine.compute_metrics(pred, gt)\n",
        "    vs = np.prod(nii.header.get_zooms()[:3]) / 1000\n",
        "\n",
        "    r = {\n",
        "        'subject_id': s['subject_id'],\n",
        "        'site': s['site'],\n",
        "        'dice': m['dice'],\n",
        "        'precision': m['precision'],\n",
        "        'recall': m['recall'],\n",
        "        'pred_ml': m['pred_voxels'] * vs,\n",
        "        'gt_ml': m['gt_voxels'] * vs,\n",
        "    }\n",
        "    test_results.append(r)\n",
        "    site_m[s['site']].append(m['dice'])\n",
        "\n",
        "    # Save NIfTI\n",
        "    out = nib.Nifti1Image(pred.astype(np.uint8),\n",
        "                          nii.affine, nii.header)\n",
        "    out.header.set_data_dtype(np.uint8)\n",
        "    nib.save(out, f\"final_{s['subject_id']}.nii.gz\")\n",
        "\n",
        "    print(f\"  [{i+1}/{len(test_subj)}] {s['subject_id']:20s} â”‚ \"\n",
        "          f\"Dice:{m['dice']:.4f} â”‚ \"\n",
        "          f\"P:{m['precision']:.3f} R:{m['recall']:.3f} â”‚ \"\n",
        "          f\"Pred:{r['pred_ml']:.2f} GT:{r['gt_ml']:.2f}mL\")\n",
        "\n",
        "ad = [r['dice'] for r in test_results]\n",
        "ap = [r['precision'] for r in test_results]\n",
        "ar = [r['recall'] for r in test_results]\n",
        "\n",
        "print(f\"\\n{'='*70}\")\n",
        "print(f\"  RESULTS\")\n",
        "print(f\"  Dice:      {np.mean(ad):.4f} Â± {np.std(ad):.4f}\")\n",
        "print(f\"  Precision: {np.mean(ap):.4f} Â± {np.std(ap):.4f}\")\n",
        "print(f\"  Recall:    {np.mean(ar):.4f} Â± {np.std(ar):.4f}\")\n",
        "print(f\"\\n  Per-site:\")\n",
        "for s in sorted(site_m):\n",
        "    d = site_m[s]\n",
        "    print(f\"    {s:12s}: {np.mean(d):.4f} Â± {np.std(d):.4f}\")\n",
        "print(f\"\\n  vs Baseline (thr=0.5): \"\n",
        "      f\"{np.mean(ad)-baseline['dice']:+.4f}\")\n",
        "print(f\"{'='*70}\")\n",
        "\n",
        "# %% [markdown]\n",
        "# # 15. Bland-Altman + Visualizations\n",
        "\n",
        "# %%\n",
        "def bland_altman(results):\n",
        "    pv = np.array([r['pred_ml'] for r in results])\n",
        "    gv = np.array([r['gt_ml'] for r in results])\n",
        "    sites = [r['site'] for r in results]\n",
        "\n",
        "    means = (pv + gv) / 2\n",
        "    diffs = pv - gv\n",
        "    md, sd = np.mean(diffs), np.std(diffs)\n",
        "    upper, lower = md + 1.96*sd, md - 1.96*sd\n",
        "\n",
        "    colors = {'Utrecht':'#e74c3c', 'Singapore':'#2ecc71',\n",
        "              'GE3T':'#3498db', 'Unknown':'#95a5a6'}\n",
        "\n",
        "    fig, (a1, a2) = plt.subplots(1, 2, figsize=(18, 7))\n",
        "\n",
        "    for site in sorted(set(sites)):\n",
        "        mk = [s == site for s in sites]\n",
        "        a1.scatter(means[mk], diffs[mk],\n",
        "                   c=colors.get(site, '#95a5a6'),\n",
        "                   s=80, alpha=0.8, edgecolors='white',\n",
        "                   label=site, zorder=3)\n",
        "    a1.axhline(md, c='k', ls='-', lw=1.5,\n",
        "               label=f'Mean:{md:.2f}')\n",
        "    a1.axhline(upper, c='gray', ls='--',\n",
        "               label=f'+1.96SD:{upper:.2f}')\n",
        "    a1.axhline(lower, c='gray', ls='--',\n",
        "               label=f'âˆ’1.96SD:{lower:.2f}')\n",
        "    a1.axhline(0, c='k', ls=':', alpha=0.3)\n",
        "    a1.set_xlabel('Mean Volume (mL)')\n",
        "    a1.set_ylabel('Predicted âˆ’ GT (mL)')\n",
        "    a1.set_title('Bland-Altman')\n",
        "    a1.legend(fontsize=9); a1.grid(alpha=0.2)\n",
        "\n",
        "    mx = max(pv.max(), gv.max()) * 1.1\n",
        "    for site in sorted(set(sites)):\n",
        "        mk = [s == site for s in sites]\n",
        "        a2.scatter(gv[mk], pv[mk],\n",
        "                   c=colors.get(site, '#95a5a6'),\n",
        "                   s=80, alpha=0.8, edgecolors='white',\n",
        "                   label=site, zorder=3)\n",
        "    a2.plot([0,mx], [0,mx], 'k--', alpha=0.5)\n",
        "    if len(gv) > 2:\n",
        "        z = np.polyfit(gv, pv, 1)\n",
        "        xf = np.linspace(0, mx, 100)\n",
        "        a2.plot(xf, np.poly1d(z)(xf), 'r-', lw=1.5)\n",
        "        ss_res = np.sum((pv - np.poly1d(z)(gv))**2)\n",
        "        ss_tot = np.sum((pv - pv.mean())**2)\n",
        "        r2 = 1 - ss_res / max(ss_tot, 1e-8)\n",
        "        a2.text(0.05, 0.92, f'RÂ²={r2:.3f}',\n",
        "                transform=a2.transAxes, fontsize=12,\n",
        "                bbox=dict(boxstyle='round', facecolor='wheat',\n",
        "                          alpha=0.8))\n",
        "    a2.set_xlabel('GT (mL)'); a2.set_ylabel('Predicted (mL)')\n",
        "    a2.set_title('Volume Correlation')\n",
        "    a2.legend(fontsize=9); a2.grid(alpha=0.2)\n",
        "    a2.set_aspect('equal')\n",
        "    a2.set_xlim(-0.5, mx); a2.set_ylim(-0.5, mx)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{BACKUP_DIR}/bland_altman.png\", dpi=150)\n",
        "    plt.show()\n",
        "    print(f\"  Bias:{md:+.3f}mL | 95%LoA:[{lower:.2f},{upper:.2f}]\")\n",
        "\n",
        "bland_altman(test_results)\n",
        "\n",
        "\n",
        "def visualize_predictions(model, ds, device, n=6):\n",
        "    model.eval()\n",
        "    li = [i for i in range(len(ds))\n",
        "          if ds.slices[i]['has_lesion']]\n",
        "    idx = np.random.choice(\n",
        "        li if len(li) >= n else len(ds), min(n, len(ds)),\n",
        "        replace=False)\n",
        "\n",
        "    fig, axes = plt.subplots(len(idx), 4,\n",
        "                             figsize=(16, 4*len(idx)))\n",
        "    if len(idx) == 1:\n",
        "        axes = axes[np.newaxis, :]\n",
        "\n",
        "    for r, i in enumerate(idx):\n",
        "        s = ds[i]\n",
        "        im = s['image'].unsqueeze(0).to(device)\n",
        "        with torch.no_grad(), torch.amp.autocast('cuda'):\n",
        "            o = model(im)\n",
        "            pn = (torch.sigmoid(o[0,0]) > 0.5\n",
        "                  ).float().cpu().numpy()\n",
        "        fn = s['image'][0].cpu().numpy()\n",
        "        mn = s['mask'][0].cpu().numpy()\n",
        "        si = ds.slices[i]\n",
        "\n",
        "        axes[r,0].imshow(fn, cmap='gray')\n",
        "        axes[r,0].set_title(\n",
        "            f\"FLAIR {si['subject_id']} z={si['slice_idx']}\",\n",
        "            fontsize=8)\n",
        "        axes[r,0].axis('off')\n",
        "\n",
        "        axes[r,1].imshow(fn, cmap='gray')\n",
        "        axes[r,1].imshow(mn, cmap='Reds', alpha=0.5)\n",
        "        axes[r,1].set_title(\"GT\"); axes[r,1].axis('off')\n",
        "\n",
        "        axes[r,2].imshow(fn, cmap='gray')\n",
        "        axes[r,2].imshow(pn, cmap='Reds', alpha=0.5)\n",
        "        axes[r,2].set_title(\"Prediction\"); axes[r,2].axis('off')\n",
        "\n",
        "        err = np.zeros_like(mn)\n",
        "        err[(mn==1) & (pn==0)] = 1\n",
        "        err[(mn==0) & (pn==1)] = 2\n",
        "        cm = mcolors.ListedColormap(['black','blue','red'])\n",
        "        nm = mcolors.BoundaryNorm([0,1,2,3], cm.N)\n",
        "        axes[r,3].imshow(err, cmap=cm, norm=nm)\n",
        "        axes[r,3].set_title(\"Error\")\n",
        "        axes[r,3].legend(\n",
        "            handles=[Patch(facecolor='blue', label='FN'),\n",
        "                     Patch(facecolor='red', label='FP')],\n",
        "            loc='upper right', fontsize=7)\n",
        "        axes[r,3].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(f\"{BACKUP_DIR}/predictions.png\", dpi=150)\n",
        "    plt.show()\n",
        "\n",
        "visualize_predictions(model, test_ds, device, n=6)\n",
        "\n",
        "# %% [markdown]\n",
        "# # 16. Final Backup\n",
        "\n",
        "# %%\n",
        "final_save = {\n",
        "    \"optimal_threshold\": float(OPT_THR),\n",
        "    \"optimal_cc\": int(best_cc),\n",
        "    \"use_tta\": USE_TTA,\n",
        "    \"config\": {\n",
        "        \"lora_rank\": LORA_RANK,\n",
        "        \"lora_alpha\": LORA_ALPHA,\n",
        "        \"epochs\": EPOCHS,\n",
        "        \"lr\": BASE_LR,\n",
        "        \"batch\": BATCH_SIZE,\n",
        "        \"accum\": ACCUM_STEPS,\n",
        "        \"gpu\": gpu_name,\n",
        "    },\n",
        "    \"baseline\": baseline,\n",
        "    \"optimized\": {\n",
        "        \"dice\": float(np.mean(ad)),\n",
        "        \"dice_std\": float(np.std(ad)),\n",
        "        \"precision\": float(np.mean(ap)),\n",
        "        \"recall\": float(np.mean(ar)),\n",
        "    },\n",
        "    \"per_subject\": [\n",
        "        {k: float(v) if isinstance(v, (np.floating, float))\n",
        "         else v for k, v in r.items()}\n",
        "        for r in test_results\n",
        "    ],\n",
        "    \"per_site\": {s: float(np.mean(d))\n",
        "                 for s, d in site_m.items()},\n",
        "}\n",
        "\n",
        "with open(f\"{BACKUP_DIR}/final_results.json\", \"w\") as f:\n",
        "    json.dump(final_save, f, indent=2, default=str)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(f\"  ALL SAVED TO: {BACKUP_DIR}\")\n",
        "print(f\"{'='*60}\")\n",
        "for item in sorted(Path(BACKUP_DIR).iterdir()):\n",
        "    sz = item.stat().st_size / 1e6\n",
        "    print(f\"  {item.name:45s} {sz:>8.1f} MB\")\n",
        "\n",
        "print(f\"\"\"\n",
        "{'='*60}\n",
        "  ULTIMATE RESULTS SUMMARY\n",
        "{'='*60}\n",
        "\n",
        "  Model:       Med-SAM ViT-B + LoRA (rank={LORA_RANK})\n",
        "  Input:       FLAIR only, {IMG_SIZE}Ã—{IMG_SIZE}\n",
        "  Loss:        Focal + Dice + Boundary + DeepSup\n",
        "  Training:    {EPOCHS} epochs, CosineWarmRestarts\n",
        "  GPU:         {gpu_name}\n",
        "\n",
        "  Baseline (thr=0.5):\n",
        "    Dice: {baseline['dice']:.4f}\n",
        "\n",
        "  Optimized (thr={OPT_THR:.2f}, CCâ‰¥{best_cc}, \\\n",
        "TTA={'ON' if USE_TTA else 'OFF'}):\n",
        "    Dice:      {np.mean(ad):.4f} Â± {np.std(ad):.4f}\n",
        "    Precision: {np.mean(ap):.4f} Â± {np.std(ap):.4f}\n",
        "    Recall:    {np.mean(ar):.4f} Â± {np.std(ar):.4f}\n",
        "\n",
        "  Improvement: {np.mean(ad)-baseline['dice']:+.4f}\n",
        "{'='*60}\n",
        "\"\"\")"
      ]
    }
  ]
}